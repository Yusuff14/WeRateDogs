{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WeRateDogs: wrangle_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this report, I will be documenting my steps in wrangling WeRateDogs data. WeRateDogs is a Twitter account that rates dogs and comments on them. There are three different datasets involved in my analysis and I will be walking us through the processes involved from beginning to the end as it all started from gathering the data.\n",
    "\n",
    "### Data Gathering\n",
    "As aforementioned, three different data were used for this analysis, of which each was gathered separately with different approaches.\n",
    "\n",
    "The three data and the approaches involved are:\n",
    "\n",
    "1. **The WeRateDog Twitter archive:** This data (twitter-archive-enhanced.csv) was available on hand and thereby downloaded manually before being uploaded into Jupyter Notebook and read into DataFrame.\n",
    "\n",
    "2. **The tweet image predictions:** This file (subsequently stored as tweet_image_predictions.tsv) is hosted on Udacity's servers and was downloaded programmatically using the Requests library . It contains the modeling outcome of each image using Neural Network.\n",
    "\n",
    "3. **The Tweet_json data:** This was created after querying the Twitter API for additional data such as favorite count, retweet count etc. These additional data were scraped from Twitter, read line by line before it was later stored as 'tweet_json.txt'.\n",
    "\n",
    "### Data Assessment\n",
    "After all the data has been gathered and loaded into the project workspace, I moved on to assessing the data visually and programmatically. Along this process, some quality and tidiness issues were observed and listed below.\n",
    "\n",
    "#### Quality issues\n",
    "##### Twitter-archive-enhanced data\n",
    "1. Erroneous datatype (column: timestamp and retweeted_status_timestamp)\n",
    "\n",
    "2. Some numerators ratings are more than expected.\n",
    "\n",
    "3. Some denominators are not 10.\n",
    "\n",
    "4. Some ratings are not tweets but retweets so remove them.\n",
    "\n",
    "5. Some ratings are not tweets but replies so remove them.\n",
    "\n",
    "6.  The columns retweeted_status_user_id, retweeted_status_user, in_reply_to_status_id are not relevant.\n",
    "\n",
    "##### Tweet_image_predictions data\n",
    " \n",
    "7. The 'tweet_id' column should not be integer but string/object.\n",
    "\n",
    "8. The predicted names of the dogs are not consisted case-wise under the columns p1, p2 and p3.\n",
    "\n",
    "#### Tidiness issues\n",
    "9. Melt the last 4 columns in twitter archive data into one column since they are redundant.\n",
    "\n",
    "10. Different tables for the same observation so we merge.\n",
    "\n",
    "### Data Cleaning\n",
    "All the observations above were not just documented but augmented with the necessary step which is cleaning the data. Each problem was dealt with separately by applying Define-Code-Test approach. This means that each observation was restated, cleaned and tested to ascertain correct output. \n",
    "\n",
    "After ensuring that all the quality and tidiness issues have been cleaned, a single dataframe was henceforth created for the three tables. This new dataset is stored as 'twitter_archive_master.csv' and it is from this that all our analysis and visualizations were created. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
